{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# for visualizing the results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for reading input data\n",
    "import pandas as pd\n",
    "\n",
    "# for parsing the FEN of chess positions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_bit_vector(fen):\n",
    "    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n",
    "    # active color - whose turn it is, either 'w' or 'b'\n",
    "    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n",
    "    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n",
    "    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n",
    "    # fullmove number - number of full turns starting at 1, increments after black's move\n",
    "\n",
    "    # Example FEN of starting position\n",
    "    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "    \n",
    "    parts = re.split(\" \", fen)\n",
    "    piece_placement = re.split(\"/\", parts[0])\n",
    "    active_color = parts[1]\n",
    "    castling_rights = parts[2]\n",
    "    en_passant = parts[3]\n",
    "    halfmove_clock = int(parts[4])\n",
    "    fullmove_clock = int(parts[5])\n",
    "\n",
    "    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n",
    "    \n",
    "    # piece to layer structure taken from reference [1]\n",
    "    piece_to_layer = {\n",
    "        'R': 1,\n",
    "        'N': 2,\n",
    "        'B': 3,\n",
    "        'Q': 4,\n",
    "        'K': 5,\n",
    "        'P': 6,\n",
    "        'p': 7,\n",
    "        'k': 8,\n",
    "        'q': 9,\n",
    "        'b': 10,\n",
    "        'n': 11,\n",
    "        'r': 12\n",
    "    }\n",
    "    \n",
    "    castling = {\n",
    "        'K': (7,7),\n",
    "        'Q': (7,0),\n",
    "        'k': (0,7),\n",
    "        'q': (0,0),\n",
    "    }\n",
    "\n",
    "    for r, row in enumerate(piece_placement):\n",
    "        c = 0\n",
    "        for piece in row:\n",
    "            if piece in piece_to_layer:\n",
    "                bit_vector[piece_to_layer[piece], r, c] = 1\n",
    "                c += 1\n",
    "            else:\n",
    "                c += int(piece)\n",
    "    \n",
    "    if en_passant != '-':\n",
    "        bit_vector[0, ord(en_passant[0]) - ord('a'), int(en_passant[1]) - 1] = 1\n",
    "    \n",
    "    if castling_rights != '-':\n",
    "        for char in castling_rights:\n",
    "            bit_vector[0, castling[char][0], castling[char][1]] = 1\n",
    "    \n",
    "    if active_color == 'w':\n",
    "        bit_vector[0, 7, 4] = 1\n",
    "    else:\n",
    "        bit_vector[0, 0, 4] = 1\n",
    "\n",
    "    if halfmove_clock > 0:\n",
    "        c = 7\n",
    "        while halfmove_clock > 0:\n",
    "            bit_vector[0, 3, c] = halfmove_clock%2\n",
    "            halfmove_clock = halfmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    if fullmove_clock > 0:\n",
    "        c = 7\n",
    "        while fullmove_clock > 0:\n",
    "            bit_vector[0, 4, c] = fullmove_clock%2\n",
    "            fullmove_clock = fullmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    return bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_board_vector(fen):\n",
    "    \"\"\"\n",
    "    We need to have a smaller representation of the board for the network to train on.\n",
    "    \"\"\"\n",
    "    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n",
    "    # active color - whose turn it is, either 'w' or 'b'\n",
    "    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n",
    "    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n",
    "    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n",
    "    # fullmove number - number of full turns starting at 1, increments after black's move\n",
    "\n",
    "    # Example FEN of starting position\n",
    "    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "    \n",
    "    parts = re.split(\" \", fen)\n",
    "    piece_placement = re.split(\"/\", parts[0])\n",
    "    active_color = parts[1]\n",
    "    castling_rights = parts[2]\n",
    "    en_passant = parts[3]\n",
    "    halfmove_clock = int(parts[4])\n",
    "    fullmove_clock = int(parts[5])\n",
    "\n",
    "    board_vector = np.zeros( (64), dtype=np.float32) # \n",
    "    \n",
    "    # piece to layer structure taken from reference [1]\n",
    "    piece_to_value = {\n",
    "        'R': 0.5,\n",
    "        'N': 0.3,\n",
    "        'B': 0.35,\n",
    "        'Q': 0.9,\n",
    "        'K': 1,\n",
    "        'P': 0.1,\n",
    "        'p': -0.1,\n",
    "        'k': -1,\n",
    "        'q': -0.9,\n",
    "        'b': -0.35,\n",
    "        'n': -0.3,\n",
    "        'r': -0.5\n",
    "    }\n",
    "    \n",
    "    castling = {\n",
    "        'K': (7,7),\n",
    "        'Q': (7,0),\n",
    "        'k': (0,7),\n",
    "        'q': (0,0),\n",
    "    }\n",
    "\n",
    "    for r, row in enumerate(piece_placement):\n",
    "        c = 0\n",
    "        for piece in row:\n",
    "            if piece in piece_to_value:\n",
    "                board_vector[r*8 + c] = piece_to_value[piece]\n",
    "                c += 1\n",
    "            else:\n",
    "                c += int(piece)\n",
    "    \n",
    "    return board_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  -0.3  -0.35 -0.9  -1.   -0.35 -0.3  -0.5  -0.1  -0.1  -0.1  -0.1\n",
      " -0.1  -0.1  -0.1  -0.1   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.5   0.3   0.35  0.9\n",
      "  1.    0.35  0.3   0.5 ]\n"
     ]
    }
   ],
   "source": [
    "fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "board = fen_to_board_vector(fen)\n",
    "print(board)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 16, bias=False)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChessDataset code and eval_to_int code taken from reference [1]\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.fens = torch.from_numpy(np.array([*map(fen_to_board_vector, data_frame[\"FEN\"])], dtype=np.float32))\n",
    "        self.evals = torch.Tensor([[x] for x in data_frame[\"Evaluation\"]])\n",
    "        self._len = len(self.evals)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.fens[index], self.evals[index]\n",
    "\n",
    "\n",
    "def eval_to_int(evaluation):\n",
    "    try:\n",
    "        res = int(evaluation)\n",
    "    except ValueError:\n",
    "        res = 10000 if evaluation[1] == '+' else -10000\n",
    "    return res / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamW_main():\n",
    "    MAX_DATA = 500000\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device {}\".format(device))\n",
    "\n",
    "    print(\"Preparing Training Data...\")\n",
    "    train_data = pd.read_csv(\"../data/chessData.csv\")\n",
    "    train_data = train_data[:MAX_DATA]\n",
    "    train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n",
    "    trainset = ChessDataset(train_data)\n",
    "    \n",
    "    print(\"Preparing Test Data...\")\n",
    "    test_data = pd.read_csv(\"../data/tactic_evals.csv\")\n",
    "    test_data = test_data[:MAX_DATA]\n",
    "    test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n",
    "    testset = ChessDataset(test_data)\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    print(\"Converting to pytorch Dataset...\")\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(net.parameters())\n",
    "\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                # denominator for loss should represent the number of positions evaluated \n",
    "                # independent of the batch size\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    PATH = './chesst_tiny_no_bias.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    print('Evaluating model')\n",
    "\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n",
    "            \n",
    "            # count should represent the number of positions evaluated \n",
    "            # independent of the batch size\n",
    "            count += len(labels)\n",
    "            total_loss += loss\n",
    "            if count % 10000 == 0:\n",
    "                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
    "    #print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Preparing Training Data...\n",
      "Preparing Test Data...\n",
      "Converting to pytorch Dataset...\n",
      "[1,  2000] loss: 2.312\n",
      "[1,  4000] loss: 2.289\n",
      "[1,  6000] loss: 2.286\n",
      "[2,  2000] loss: 2.249\n",
      "[2,  4000] loss: 2.215\n",
      "[2,  6000] loss: 2.221\n",
      "[3,  2000] loss: 2.193\n",
      "[3,  4000] loss: 2.251\n",
      "[3,  6000] loss: 2.066\n",
      "[4,  2000] loss: 2.118\n",
      "[4,  4000] loss: 2.105\n",
      "[4,  6000] loss: 2.148\n",
      "[5,  2000] loss: 2.057\n",
      "[5,  4000] loss: 2.124\n",
      "[5,  6000] loss: 2.147\n",
      "[6,  2000] loss: 2.066\n",
      "[6,  4000] loss: 2.062\n",
      "[6,  6000] loss: 2.102\n",
      "[7,  2000] loss: 1.955\n",
      "[7,  4000] loss: 2.120\n",
      "[7,  6000] loss: 2.100\n",
      "[8,  2000] loss: 2.111\n",
      "[8,  4000] loss: 2.041\n",
      "[8,  6000] loss: 2.010\n",
      "[9,  2000] loss: 2.017\n",
      "[9,  4000] loss: 2.072\n",
      "[9,  6000] loss: 2.070\n",
      "[10,  2000] loss: 2.030\n",
      "[10,  4000] loss: 2.032\n",
      "[10,  6000] loss: 1.978\n",
      "Finished Training\n",
      "Evaluating model\n",
      "Average error of the model on the 40000 tactics positions is 0.061318784952163696\n",
      "Average error of the model on the 80000 tactics positions is 0.014967724680900574\n",
      "Average error of the model on the 120000 tactics positions is 0.023405421525239944\n",
      "Average error of the model on the 160000 tactics positions is 0.025191357359290123\n",
      "Average error of the model on the 200000 tactics positions is 0.014591478742659092\n",
      "Average error of the model on the 240000 tactics positions is 0.019773662090301514\n",
      "Average error of the model on the 280000 tactics positions is 0.0024366830475628376\n",
      "Average error of the model on the 320000 tactics positions is 0.0061334967613220215\n",
      "Average error of the model on the 360000 tactics positions is 0.004616988822817802\n",
      "Average error of the model on the 400000 tactics positions is 0.007329368498176336\n",
      "Average error of the model on the 440000 tactics positions is 0.00630110502243042\n",
      "Average error of the model on the 480000 tactics positions is 0.004920482635498047\n",
      "Average error of the model on the 500000 tactics positions is 0.010851920582354069\n"
     ]
    }
   ],
   "source": [
    "AdamW_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chess.pth:\n",
    "Evaluating model\n",
    "Average error of the model on the 40000 tactics positions is 0.0609552226960659\n",
    "Average error of the model on the 80000 tactics positions is 0.016548501327633858\n",
    "Average error of the model on the 100000 tactics positions is 0.03276893123984337\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mtrang/Documents/rl/Chess-Challenge/devel/notebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import BSpline\n",
    "\n",
    "# Assuming you have a dataset with 64 variables and a single output\n",
    "# You can represent your dataset as a NumPy array, where each row is a data point\n",
    "# and the last column contains the output values.\n",
    "\n",
    "# Generate a sample dataset for demonstration purposes\n",
    "num_data_points = 100\n",
    "num_variables = 64\n",
    "\n",
    "# Generate random input data\n",
    "\n",
    "train_data = pd.read_csv(\"../data/chessData.csv\")\n",
    "\n",
    "MAX_DATA = 50000\n",
    "train_data = train_data[:MAX_DATA]\n",
    "train_data[\"FEN\"] = train_data[\"FEN\"].map(fen_to_board_vector)\n",
    "train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n",
    "input_data = train_data[\"FEN\"]\n",
    "\n",
    "# Generate random output data\n",
    "output_data = train_data[\"Evaluation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Output:\n",
      "[-259782.6107742   -93262.75236078  -29228.78977574 ...   26761.61759621\n",
      "   86180.69226667  241982.53372402]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sort the data points based on the input variable of interest (e.g., the first variable)\n",
    "sorted_indices = np.arange(len(input_data), dtype=np.int64)\n",
    "sorted_input_data = input_data[sorted_indices]\n",
    "sorted_output_data = output_data[sorted_indices]\n",
    "\n",
    "# Define the degree of the spline (eighth degree)\n",
    "degree = 8\n",
    "\n",
    "# Create a B-spline object with the specified degree\n",
    "k = degree + 1\n",
    "t = np.linspace(0, 1, len(sorted_input_data))\n",
    "spl = BSpline(t, sorted_output_data, k, extrapolate=True)\n",
    "\n",
    "# Generate some test input values for interpolation\n",
    "test_input = np.random.rand(10, num_variables)\n",
    "\n",
    "# Interpolate the output values for the test input using the spline\n",
    "interpolated_output = spl(t)\n",
    "\n",
    "# Print the interpolated output\n",
    "print(\"Interpolated Output:\")\n",
    "print(interpolated_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import numpy\n",
    "\n",
    "\"\"\"\n",
    "Given the following function:\n",
    "    y = f(w1:w6) = w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + 6wx6\n",
    "    where (x1,x2,x3,x4,x5,x6)=(4,-2,3.5,5,-11,-4.7) and y=44\n",
    "What are the best values for the 6 weights (w1 to w6)? We are going to use the genetic algorithm to optimize this function.\n",
    "\"\"\"\n",
    "\n",
    "function_inputs = [4,-2,3.5,5,-11,-4.7] # Function inputs.\n",
    "desired_output = 44 # Function output.\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    # Calculating the fitness value of each solution in the current population.\n",
    "    # The fitness function calulates the sum of products between each input and its corresponding weight.\n",
    "    output = numpy.sum(solution*function_inputs)\n",
    "    fitness = 1.0 / numpy.abs(output - desired_output)\n",
    "    return fitness\n",
    "\n",
    "fitness_function = fitness_func\n",
    "\n",
    "num_generations = 100 # Number of generations.\n",
    "num_parents_mating = 7 # Number of solutions to be selected as parents in the mating pool.\n",
    "\n",
    "# To prepare the initial population, there are 2 ways:\n",
    "# 1) Prepare it yourself and pass it to the initial_population parameter. This way is useful when the user wants to start the genetic algorithm with a custom initial population.\n",
    "# 2) Assign valid integer values to the sol_per_pop and num_genes parameters. If the initial_population parameter exists, then the sol_per_pop and num_genes parameters are useless.\n",
    "sol_per_pop = 50 # Number of solutions in the population.\n",
    "num_genes = len(function_inputs)\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
    "    last_fitness = ga_instance.best_solution()[1]\n",
    "\n",
    "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop, \n",
    "                       num_genes=num_genes,\n",
    "                       on_generation=callback_generation)\n",
    "\n",
    "# Running the GA to optimize the parameters of the function.\n",
    "ga_instance.run()\n",
    "\n",
    "# After the generations complete, some plots are showed that summarize the how the outputs/fitenss values evolve over generations.\n",
    "ga_instance.plot_fitness()\n",
    "\n",
    "# Returning the details of the best solution.\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
    "\n",
    "prediction = numpy.sum(numpy.array(function_inputs)*solution)\n",
    "print(\"Predicted output based on the best solution : {prediction}\".format(prediction=prediction))\n",
    "\n",
    "if ga_instance.best_solution_generation != -1:\n",
    "    print(\"Best fitness value reached after {best_solution_generation} generations.\".format(best_solution_generation=ga_instance.best_solution_generation))\n",
    "\n",
    "# Saving the GA instance.\n",
    "filename = 'genetic' # The filename to which the instance is saved. The name is without extension.\n",
    "ga_instance.save(filename=filename)\n",
    "\n",
    "# Loading the saved GA instance.\n",
    "loaded_ga_instance = pygad.load(filename=filename)\n",
    "loaded_ga_instance.plot_fitness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
