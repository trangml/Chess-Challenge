{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# for visualizing the results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for reading input data\n",
    "import pandas as pd\n",
    "\n",
    "# for parsing the FEN of chess positions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_bit_vector(fen):\n",
    "    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n",
    "    # active color - whose turn it is, either 'w' or 'b'\n",
    "    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n",
    "    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n",
    "    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n",
    "    # fullmove number - number of full turns starting at 1, increments after black's move\n",
    "\n",
    "    # Example FEN of starting position\n",
    "    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "    \n",
    "    parts = re.split(\" \", fen)\n",
    "    piece_placement = re.split(\"/\", parts[0])\n",
    "    active_color = parts[1]\n",
    "    castling_rights = parts[2]\n",
    "    en_passant = parts[3]\n",
    "    halfmove_clock = int(parts[4])\n",
    "    fullmove_clock = int(parts[5])\n",
    "\n",
    "    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n",
    "    \n",
    "    # piece to layer structure taken from reference [1]\n",
    "    piece_to_layer = {\n",
    "        'R': 1,\n",
    "        'N': 2,\n",
    "        'B': 3,\n",
    "        'Q': 4,\n",
    "        'K': 5,\n",
    "        'P': 6,\n",
    "        'p': 7,\n",
    "        'k': 8,\n",
    "        'q': 9,\n",
    "        'b': 10,\n",
    "        'n': 11,\n",
    "        'r': 12\n",
    "    }\n",
    "    \n",
    "    castling = {\n",
    "        'K': (7,7),\n",
    "        'Q': (7,0),\n",
    "        'k': (0,7),\n",
    "        'q': (0,0),\n",
    "    }\n",
    "\n",
    "    for r, row in enumerate(piece_placement):\n",
    "        c = 0\n",
    "        for piece in row:\n",
    "            if piece in piece_to_layer:\n",
    "                bit_vector[piece_to_layer[piece], r, c] = 1\n",
    "                c += 1\n",
    "            else:\n",
    "                c += int(piece)\n",
    "    \n",
    "    if en_passant != '-':\n",
    "        bit_vector[0, ord(en_passant[0]) - ord('a'), int(en_passant[1]) - 1] = 1\n",
    "    \n",
    "    if castling_rights != '-':\n",
    "        for char in castling_rights:\n",
    "            bit_vector[0, castling[char][0], castling[char][1]] = 1\n",
    "    \n",
    "    if active_color == 'w':\n",
    "        bit_vector[0, 7, 4] = 1\n",
    "    else:\n",
    "        bit_vector[0, 0, 4] = 1\n",
    "\n",
    "    if halfmove_clock > 0:\n",
    "        c = 7\n",
    "        while halfmove_clock > 0:\n",
    "            bit_vector[0, 3, c] = halfmove_clock%2\n",
    "            halfmove_clock = halfmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    if fullmove_clock > 0:\n",
    "        c = 7\n",
    "        while fullmove_clock > 0:\n",
    "            bit_vector[0, 4, c] = fullmove_clock%2\n",
    "            fullmove_clock = fullmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    return bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_board_vector(fen):\n",
    "    \"\"\"\n",
    "    We need to have a smaller representation of the board for the network to train on.\n",
    "    \"\"\"\n",
    "    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n",
    "    # active color - whose turn it is, either 'w' or 'b'\n",
    "    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n",
    "    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n",
    "    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n",
    "    # fullmove number - number of full turns starting at 1, increments after black's move\n",
    "\n",
    "    # Example FEN of starting position\n",
    "    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "    \n",
    "    parts = re.split(\" \", fen)\n",
    "    piece_placement = re.split(\"/\", parts[0])\n",
    "    active_color = parts[1]\n",
    "    castling_rights = parts[2]\n",
    "    en_passant = parts[3]\n",
    "    halfmove_clock = int(parts[4])\n",
    "    fullmove_clock = int(parts[5])\n",
    "\n",
    "    board_vector = np.zeros( (8,8), dtype=np.float32) # \n",
    "    \n",
    "    # piece to layer structure taken from reference [1]\n",
    "    piece_to_value = {\n",
    "        'R': 0.5,\n",
    "        'N': 0.3,\n",
    "        'B': 0.35,\n",
    "        'Q': 0.9,\n",
    "        'K': 1,\n",
    "        'P': 0.1,\n",
    "        'p': -0.1,\n",
    "        'k': -1,\n",
    "        'q': -0.9,\n",
    "        'b': -0.35,\n",
    "        'n': -0.3,\n",
    "        'r': -0.5\n",
    "    }\n",
    "    \n",
    "    castling = {\n",
    "        'K': (7,7),\n",
    "        'Q': (7,0),\n",
    "        'k': (0,7),\n",
    "        'q': (0,0),\n",
    "    }\n",
    "\n",
    "    for r, row in enumerate(piece_placement):\n",
    "        c = 0\n",
    "        for piece in row:\n",
    "            if piece in piece_to_value:\n",
    "                board_vector[r, c] = piece_to_value[piece]\n",
    "                c += 1\n",
    "            else:\n",
    "                c += int(piece)\n",
    "    \n",
    "    return board_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  -0.3  -0.35 -0.9  -1.   -0.35 -0.3  -0.5  -0.1  -0.1  -0.1  -0.1\n",
      " -0.1  -0.1  -0.1  -0.1   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.5   0.3   0.35  0.9\n",
      "  1.    0.35  0.3   0.5 ]\n"
     ]
    }
   ],
   "source": [
    "fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "board = fen_to_board_vector(fen)\n",
    "board=board.flatten()\n",
    "print(board)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChessDataset code and eval_to_int code taken from reference [1]\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.fens = torch.from_numpy(np.array([*map(fen_to_board_vector, data_frame[\"FEN\"])], dtype=np.float32))\n",
    "        self.evals = torch.Tensor([[x] for x in data_frame[\"Evaluation\"]])\n",
    "        self._len = len(self.evals)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.fens[index], self.evals[index]\n",
    "\n",
    "\n",
    "def eval_to_int(evaluation):\n",
    "    try:\n",
    "        res = int(evaluation)\n",
    "    except ValueError:\n",
    "        res = 10000 if evaluation[1] == '+' else -10000\n",
    "    return res / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamW_main():\n",
    "    MAX_DATA = 100000\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device {}\".format(device))\n",
    "\n",
    "    print(\"Preparing Training Data...\")\n",
    "    train_data = pd.read_csv(\"../data/chessData.csv\")\n",
    "    train_data = train_data[:MAX_DATA]\n",
    "    train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n",
    "    trainset = ChessDataset(train_data)\n",
    "    \n",
    "    print(\"Preparing Test Data...\")\n",
    "    test_data = pd.read_csv(\"../data/tactic_evals.csv\")\n",
    "    test_data = test_data[:MAX_DATA]\n",
    "    test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n",
    "    testset = ChessDataset(test_data)\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    print(\"Converting to pytorch Dataset...\")\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(net.parameters())\n",
    "\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                # denominator for loss should represent the number of positions evaluated \n",
    "                # independent of the batch size\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    PATH = './chess.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    print('Evaluating model')\n",
    "\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n",
    "            \n",
    "            # count should represent the number of positions evaluated \n",
    "            # independent of the batch size\n",
    "            count += len(labels)\n",
    "            total_loss += loss\n",
    "            if count % 10000 == 0:\n",
    "                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
    "    #print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Preparing Training Data...\n",
      "Preparing Test Data...\n",
      "Converting to pytorch Dataset...\n",
      "[1,  2000] loss: 8.809\n",
      "[1,  4000] loss: 8.467\n",
      "[1,  6000] loss: 9.202\n",
      "[1,  8000] loss: 8.889\n",
      "[1, 10000] loss: 8.545\n",
      "[2,  2000] loss: 7.595\n",
      "[2,  4000] loss: 8.179\n",
      "[2,  6000] loss: 7.174\n",
      "[2,  8000] loss: 7.402\n",
      "[2, 10000] loss: 6.552\n",
      "[3,  2000] loss: 6.254\n",
      "[3,  4000] loss: 6.474\n",
      "[3,  6000] loss: 6.698\n",
      "[3,  8000] loss: 6.344\n",
      "[3, 10000] loss: 6.470\n",
      "[4,  2000] loss: 5.367\n",
      "[4,  4000] loss: 6.230\n",
      "[4,  6000] loss: 6.126\n",
      "[4,  8000] loss: 5.975\n",
      "[4, 10000] loss: 5.676\n",
      "[5,  2000] loss: 5.602\n",
      "[5,  4000] loss: 5.398\n",
      "[5,  6000] loss: 5.311\n",
      "[5,  8000] loss: 5.918\n",
      "[5, 10000] loss: 5.222\n",
      "[6,  2000] loss: 4.886\n",
      "[6,  4000] loss: 5.071\n",
      "[6,  6000] loss: 5.230\n",
      "[6,  8000] loss: 5.235\n",
      "[6, 10000] loss: 5.184\n",
      "[7,  2000] loss: 4.605\n",
      "[7,  4000] loss: 4.495\n",
      "[7,  6000] loss: 4.911\n",
      "[7,  8000] loss: 5.088\n",
      "[7, 10000] loss: 5.075\n",
      "[8,  2000] loss: 4.687\n",
      "[8,  4000] loss: 4.874\n",
      "[8,  6000] loss: 4.039\n",
      "[8,  8000] loss: 4.809\n",
      "[8, 10000] loss: 4.695\n",
      "[9,  2000] loss: 3.907\n",
      "[9,  4000] loss: 4.609\n",
      "[9,  6000] loss: 4.433\n",
      "[9,  8000] loss: 4.498\n",
      "[9, 10000] loss: 4.573\n",
      "[10,  2000] loss: 4.116\n",
      "[10,  4000] loss: 4.159\n",
      "[10,  6000] loss: 4.244\n",
      "[10,  8000] loss: 4.412\n",
      "[10, 10000] loss: 4.213\n",
      "Finished Training\n",
      "Evaluating model\n",
      "Average error of the model on the 10000 tactics positions is 0.1015898585319519\n",
      "Average error of the model on the 20000 tactics positions is 0.00192842457909137\n",
      "Average error of the model on the 30000 tactics positions is 0.0005505987792275846\n",
      "Average error of the model on the 40000 tactics positions is 0.00037067863740958273\n",
      "Average error of the model on the 50000 tactics positions is 0.0007962691015563905\n",
      "Average error of the model on the 60000 tactics positions is 0.0007808466325514019\n",
      "Average error of the model on the 70000 tactics positions is 0.03831375390291214\n",
      "Average error of the model on the 80000 tactics positions is 0.026961790397763252\n",
      "Average error of the model on the 90000 tactics positions is 0.024838918820023537\n",
      "Average error of the model on the 100000 tactics positions is 0.019848376512527466\n"
     ]
    }
   ],
   "source": [
    "AdamW_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mtrang/Documents/rl/Chess-Challenge/devel/notebooks'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
